DEVICE          : cuda              # device used for training and evaluation (cpu, cuda, cuda0, cuda1, ...)
SAVE_DIR        : 'output'         # output folder name used for saving the model, logs and inference results

MODEL:                                    
  NAME          : Devign                                        # name of the model you are using
  BACKBONE      :
  PARAMS:                                                   # model variant
    encoder       : 
    config        :
    tokenizer     : 'roberta'
    args          :
        gated_graph_conv_args:
          out_channels: 200
          num_layers: 6
          aggr: 'add'
          bias: true
        conv_args:
          conv1d_1:
            in_channels: 205
            out_channels: 50
            kernel_size: 3
            padding: 1
          conv1d_2:
            in_channels: 50
            out_channels: 20
            kernel_size: 1
            padding: 1
          maxpool1d_1:
            kernel_size: 3
            stride: 2
          maxpool1d_2:
            kernel_size: 2
            stride: 2
        emb_size: 101
  PRETRAINED    : 'checkpoints/backbones/xx.pth'              # backbone model's weight 

DATASET:
  NAME          : ReGVD                                         # dataset name to be trained
  ROOT          : ''                         # dataset root path
  PARAMS:
    tokenizer   : 'roberta'
    args        :
      train_data_file: '/root/autodl-fs/dataset/train.jsonl'
      eval_data_file : '/root/autodl-fs/dataset/valid.jsonl'
      test_data_file : '/root/autodl-fs/dataset/test.jsonl'
      block_size     : 400
      training_percent: 1.0
  PREPROCESS:
    ENABLE      : False
    COMPOSE     : [ 
                "Normalize",
                "PadSequence",
                "OneHotEncode"
        ]
      


TRAIN:
  INPUT_SIZE    : 128
  BATCH_SIZE    : 128               # batch size used to train
  EPOCHS        : 20             # number of epochs to train
  EVAL_INTERVAL : 50              # evaluation interval during training
  AMP           : false           # use AMP in training
  DDP           : false           # use DDP training

LOSS:
  NAME          : CrossEntropy          # loss function name (ohemce, ce, dice)
  CLS_WEIGHTS   : false            # use class weights in loss calculation

OPTIMIZER:
  NAME          : adamw           # optimizer name
  LR            : 0.001           # initial learning rate used in optimizer
  WEIGHT_DECAY  : 0.01            # decay rate used in optimizer 

SCHEDULER:
  NAME          : warmuppolylr    # scheduler name
  POWER         : 0.9             # scheduler power
  WARMUP        : 10              # warmup epochs used in scheduler
  WARMUP_RATIO  : 0.1             # warmup ratio
  

EVAL:
  INPUT_SIZE    : 128
  MODEL_PATH    : 'checkpoints/pretrained/a.pth'  # trained model file path
  MSF: 
    ENABLE      : false                                                                 # multi-scale and flip evaluation  
    FLIP        : true                                                                  # use flip in evaluation  
    SCALES      : [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]                                     # scales used in MSF evaluation                


TEST:
  MODEL_PATH    : 'checkpoints/pretrained/a.pth'  # trained model file path
  FILE          : 'assests/ade'                                                         # filename or foldername 
  INPUT_SIZE    : 128                                                            # inference input size
  OVERLAY       : true                                                                  # save the result
